{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Lab 6: Evaluating & Tuning Diagnosisifiers (TA Version)\n",
        "\n",
        "## TA Guidance\n",
        "\n",
        "> **TA Instructions:**  \n",
        "> 1. Have **students** render the **Student Version** of this lab. They\n",
        "> will see minimal commentary—just the tasks and essential\n",
        "> instructions.  \n",
        "> 2. **You**, as the teaching assistant, should keep *this* **TA\n",
        "> Version** open in another tab/window. It contains additional\n",
        "> commentary and tips for each step, as well as clarifications to help\n",
        "> you guide the lab session effectively.  \n",
        "> 3. Point out important details from your side, but do not show\n",
        "> students the entire TA text.  \n",
        "> 4. Encourage them to read the reference chapters (Chapters 2–3 on data\n",
        "> loading/inspection and Chapter 6 on classification evaluation and\n",
        "> tuning).  \n",
        "> 5. Emphasize the difference between a baseline model and a tuned\n",
        "> model, ensuring they understand the concept of not peeking at the test\n",
        "> set.  \n",
        "> 6. At the end, you can discuss the reflection questions as a group,\n",
        "> focusing on the real-world implications of classification performance.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Objective\n",
        "\n",
        "In this lab, students will learn how to evaluate and tune a K‑nearest\n",
        "neighbors (KNN) Diagnosisifier. They will:\n",
        "\n",
        "-   Load and inspect the breast cancer dataset.\n",
        "-   Split the data into training and test sets (using stratified\n",
        "    sampling).\n",
        "-   Preprocess the data by standardizing selected features.\n",
        "-   Build a baseline KNN Diagnosisifier and evaluate its performance\n",
        "    using accuracy, precision, recall, and a confusion matrix.\n",
        "-   Tune the Diagnosisifier using GridSearchCV with cross-validation.\n",
        "\n",
        "> **Reference for Students (Chapters 2–3, 6)**: *Data Science: A First\n",
        "> Introduction with Python*\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "### TA Note\n",
        "\n",
        "-   **Goal**: Students get practice building a classifier, splitting\n",
        "    data, evaluating performance, and applying hyperparameter tuning\n",
        "    with cross-validation.  \n",
        "-   **Key Emphasis**:\n",
        "    -   Reproducibility (set `random_state` for `train_test_split` or\n",
        "        `np.random.seed`).  \n",
        "    -   Importance of not using the test set until the very end.  \n",
        "    -   Use of standardization in a pipeline so as not to contaminate\n",
        "        training vs. test data.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Step 1. Data Loading and Inspection\n",
        "\n",
        "**TA Note**:  \n",
        "- Remind students to verify the CSV path and watch for spelling\n",
        "errors.  \n",
        "- Encourage them to confirm class distributions—**Benign**\n",
        "vs. **Malignant**.  \n",
        "- Stress how Pandas `info()` or `describe()` can help them understand\n",
        "the dataset shape and any missing data."
      ],
      "id": "7265872e-f985-45a5-bd8c-d07a10be123a"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 rows of the cancer dataset:\n",
            "         ID  Diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
            "0    842302  Malignant        17.99         10.38          122.80     1001.0   \n",
            "1    842517  Malignant        20.57         17.77          132.90     1326.0   \n",
            "2  84300903  Malignant        19.69         21.25          130.00     1203.0   \n",
            "3  84348301  Malignant        11.42         20.38           77.58      386.1   \n",
            "4  84358402  Malignant        20.29         14.34          135.10     1297.0   \n",
            "\n",
            "   smoothness_mean  compactness_mean  concavity_mean  concave_points_mean  \\\n",
            "0          0.11840           0.27760          0.3001              0.14710   \n",
            "1          0.08474           0.07864          0.0869              0.07017   \n",
            "2          0.10960           0.15990          0.1974              0.12790   \n",
            "3          0.14250           0.28390          0.2414              0.10520   \n",
            "4          0.10030           0.13280          0.1980              0.10430   \n",
            "\n",
            "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
            "0  ...         25.38          17.33           184.60      2019.0   \n",
            "1  ...         24.99          23.41           158.80      1956.0   \n",
            "2  ...         23.57          25.53           152.50      1709.0   \n",
            "3  ...         14.91          26.50            98.87       567.7   \n",
            "4  ...         22.54          16.67           152.20      1575.0   \n",
            "\n",
            "   smoothness_worst  compactness_worst  concavity_worst  concave_points_worst  \\\n",
            "0            0.1622             0.6656           0.7119                0.2654   \n",
            "1            0.1238             0.1866           0.2416                0.1860   \n",
            "2            0.1444             0.4245           0.4504                0.2430   \n",
            "3            0.2098             0.8663           0.6869                0.2575   \n",
            "4            0.1374             0.2050           0.4000                0.1625   \n",
            "\n",
            "   symmetry_worst  fractal_dimension_worst  \n",
            "0          0.4601                  0.11890  \n",
            "1          0.2750                  0.08902  \n",
            "2          0.3613                  0.08758  \n",
            "3          0.6638                  0.17300  \n",
            "4          0.2364                  0.07678  \n",
            "\n",
            "[5 rows x 32 columns]\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 569 entries, 0 to 568\n",
            "Data columns (total 32 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   ID                       569 non-null    int64  \n",
            " 1   Diagnosis                569 non-null    object \n",
            " 2   radius_mean              569 non-null    float64\n",
            " 3   texture_mean             569 non-null    float64\n",
            " 4   perimeter_mean           569 non-null    float64\n",
            " 5   area_mean                569 non-null    float64\n",
            " 6   smoothness_mean          569 non-null    float64\n",
            " 7   compactness_mean         569 non-null    float64\n",
            " 8   concavity_mean           569 non-null    float64\n",
            " 9   concave_points_mean      569 non-null    float64\n",
            " 10  symmetry_mean            569 non-null    float64\n",
            " 11  fractal_dimension_mean   569 non-null    float64\n",
            " 12  radius_se                569 non-null    float64\n",
            " 13  texture_se               569 non-null    float64\n",
            " 14  perimeter_se             569 non-null    float64\n",
            " 15  area_se                  569 non-null    float64\n",
            " 16  smoothness_se            569 non-null    float64\n",
            " 17  compactness_se           569 non-null    float64\n",
            " 18  concavity_se             569 non-null    float64\n",
            " 19  concave_points_se        569 non-null    float64\n",
            " 20  symmetry_se              569 non-null    float64\n",
            " 21  fractal_dimension_se     569 non-null    float64\n",
            " 22  radius_worst             569 non-null    float64\n",
            " 23  texture_worst            569 non-null    float64\n",
            " 24  perimeter_worst          569 non-null    float64\n",
            " 25  area_worst               569 non-null    float64\n",
            " 26  smoothness_worst         569 non-null    float64\n",
            " 27  compactness_worst        569 non-null    float64\n",
            " 28  concavity_worst          569 non-null    float64\n",
            " 29  concave_points_worst     569 non-null    float64\n",
            " 30  symmetry_worst           569 non-null    float64\n",
            " 31  fractal_dimension_worst  569 non-null    float64\n",
            "dtypes: float64(30), int64(1), object(1)\n",
            "memory usage: 142.4+ KB\n",
            "None"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np  # We'll use NumPy for setting the random seed\n",
        "\n",
        "# Modeling imports\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import make_column_transformer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "# TA: We are using the WDBC breast cancer dataset.\n",
        "cancer = pd.read_csv(\"wdbc.csv\")\n",
        "\n",
        "# Replace shorthand labels with full names.\n",
        "cancer[\"Diagnosis\"] = cancer[\"Diagnosis\"].replace({\"M\": \"Malignant\", \"B\": \"Benign\"})\n",
        "\n",
        "print(\"First 5 rows of the cancer dataset:\")\n",
        "print(cancer.head())\n",
        "\n",
        "print(\"\\nDataset Info:\")\n",
        "print(cancer.info())"
      ],
      "id": "e0e5a2e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Step 2. Preprocessing and Train/Test Split\n",
        "\n",
        "**TA Note**:  \n",
        "- Emphasize why we do **train/test splits** *before* tuning.  \n",
        "- Show them how `stratify=cancer[\"Diagnosis\"]` keeps class proportions\n",
        "consistent.  \n",
        "- They should note the shapes of both splits and confirm they add up to\n",
        "the original size."
      ],
      "id": "3da7f51b-d6d3-4b3c-944f-f154af89072b"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set shape: (426, 32)\n",
            "Test set shape: (143, 32)"
          ]
        }
      ],
      "source": [
        "# TA: random_state for reproducibility\n",
        "cancer_train, cancer_test = train_test_split(\n",
        "    cancer, train_size=0.75, stratify=cancer[\"Diagnosis\"], random_state=1\n",
        ")\n",
        "\n",
        "print(\"Training set shape:\", cancer_train.shape)\n",
        "print(\"Test set shape:\", cancer_test.shape)\n",
        "\n",
        "# TA: Only standardize the features \"area_mean\" and \"smoothness_mean\" for illustration.\n",
        "preprocessor = make_column_transformer(\n",
        "    (StandardScaler(), [\"area_mean\", \"smoothness_mean\"])\n",
        ")"
      ],
      "id": "fee933a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Step 3. Building and Evaluating the Baseline Diagnosisifier\n",
        "\n",
        "**TA Note**:  \n",
        "- Students need to see how to do a “basic” classification with\n",
        "`KNeighborsClassifier(n_neighbors=5)`.  \n",
        "- Encourage them to interpret the code: build pipeline → fit →\n",
        "evaluate.  \n",
        "- They’ll see “accuracy” from `score`. We can define advanced metrics\n",
        "(precision, recall) if time permits."
      ],
      "id": "426c92a1-58e1-4596-b0c9-e0f55edf79bb"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNN pipeline trained (k=5).\n",
            "Baseline test set accuracy (k=5): 0.9020979020979021"
          ]
        }
      ],
      "source": [
        "# TA: KNN with k=5 as baseline\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_pipeline = make_pipeline(preprocessor, knn)\n",
        "\n",
        "X_train = cancer_train[[\"area_mean\", \"smoothness_mean\"]]\n",
        "y_train = cancer_train[\"Diagnosis\"]\n",
        "\n",
        "# Train (fit) baseline model\n",
        "knn_pipeline.fit(X_train, y_train)\n",
        "print(\"KNN pipeline trained (k=5).\")\n",
        "\n",
        "# Evaluate on test set\n",
        "X_test = cancer_test[[\"area_mean\", \"smoothness_mean\"]]\n",
        "y_test = cancer_test[\"Diagnosis\"]\n",
        "baseline_accuracy = knn_pipeline.score(X_test, y_test)\n",
        "print(\"Baseline test set accuracy (k=5):\", baseline_accuracy)"
      ],
      "id": "ccba5797"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Step 4. Tuning the Diagnosisifier with GridSearchCV\n",
        "\n",
        "**TA Note**:  \n",
        "- Explain `GridSearchCV` is a systematic approach to try multiple `k`\n",
        "values.  \n",
        "- Stress that cross-validation is a strategy to avoid overfitting to\n",
        "training data.  \n",
        "- We keep `cv=10` folds; mention we can tweak folds if needed."
      ],
      "id": "8cbe8d03-9584-4577-93fc-4d36f8b9ded3"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found: {'kneighborsclassifier__n_neighbors': 21}\n",
            "Best cross-validation accuracy: 0.8897563676633444"
          ]
        }
      ],
      "source": [
        "parameter_grid = {\"kneighborsclassifier__n_neighbors\": range(1, 100, 5)}\n",
        "\n",
        "# New pipeline for tuning\n",
        "knn_for_tuning = KNeighborsClassifier()\n",
        "tune_pipeline = make_pipeline(preprocessor, knn_for_tuning)\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=tune_pipeline,\n",
        "    param_grid=parameter_grid,\n",
        "    cv=10,\n",
        "    n_jobs=-1  # speed\n",
        ")\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best parameters found:\", grid_search.best_params_)\n",
        "print(\"Best cross-validation accuracy:\", grid_search.best_score_)"
      ],
      "id": "12ba5cd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## (Bonus!) Quick Glimpse of Cross-Validation Directly\n",
        "\n",
        "**TA Note**:  \n",
        "- This snippet is optional. Good to demonstrate the direct use of\n",
        "`cross_val_score` if students want a quick measure of how well a model\n",
        "might perform."
      ],
      "id": "a542a601-1d13-456b-bbca-317bce026003"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93023256 0.84705882 0.81176471 0.81176471 0.88235294]\n",
            "Mean cross-validation accuracy: 0.8566347469220247"
          ]
        }
      ],
      "source": [
        "cv_scores = cross_val_score(tune_pipeline, X_train, y_train, cv=5)\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "print(\"Mean cross-validation accuracy:\", cv_scores.mean())"
      ],
      "id": "fd67a2a0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Step 5. Evaluating the Tuned Model\n",
        "\n",
        "**TA Note**:  \n",
        "- This is where we do a final test-set evaluation with the chosen `k`.  \n",
        "- Students should see how test-set results might differ from\n",
        "cross-validation.  \n",
        "- Encourage them to examine confusion matrices to see types of error."
      ],
      "id": "016e41bd-f607-452a-a671-aa1fb1511974"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy (tuned model): 0.9230769230769231\n",
            "Confusion Matrix:\n",
            "predicted  Benign  Malignant\n",
            "Diagnosis                   \n",
            "Benign         88          2\n",
            "Malignant       9         44"
          ]
        }
      ],
      "source": [
        "# Predict on the test set\n",
        "cancer_test[\"predicted\"] = grid_search.predict(X_test)\n",
        "\n",
        "# Test accuracy of tuned model\n",
        "tuned_accuracy = grid_search.score(X_test, y_test)\n",
        "print(\"Test set accuracy (tuned model):\", tuned_accuracy)\n",
        "\n",
        "# Confusion matrix\n",
        "conf_matrix = pd.crosstab(cancer_test[\"Diagnosis\"], cancer_test[\"predicted\"])\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "id": "0ffd04ce"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "------------------------------------------------------------------------\n",
        "\n",
        "## Final Reflection & Extension\n",
        "\n",
        "**TA Note**:  \n",
        "- Guide students to connect evaluation metrics to real-world impacts\n",
        "(especially misclassification in medical contexts).  \n",
        "- Ensure they reflect on how the final accuracy compares to the\n",
        "baseline.  \n",
        "- If time remains, show how `precision_score` and `recall_score` can add\n",
        "insight—especially when diagnosing serious conditions.\n",
        "\n",
        "**For Students**:  \n",
        "1. Compare your baseline test accuracy to the tuned model’s test\n",
        "accuracy. Did tuning help?  \n",
        "2. Why is cross‑validation used in the tuning step instead of just\n",
        "reusing the test set?  \n",
        "3. Interpret the confusion matrix. Where are **false negatives** and\n",
        "**false positives**? Are they equally important for tumor diagnoses?  \n",
        "4. In real‑life medical contexts, consider if it’s riskier to have a\n",
        "false negative or a false positive. Reflect on how you might adjust your\n",
        "approach (e.g., focusing on recall vs. precision).\n",
        "\n",
        "**Bonus**  \n",
        "- Plot accuracy vs. $k$ to see if you can spot overfitting\n",
        "vs. underfitting patterns."
      ],
      "id": "58cce1d9-aa7c-4392-af09-8e277895645f"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/Users/briancervantesalvarez/anaconda3/share/jupyter/kernels/python3"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  }
}